{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "538626cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} pytorch-lightning\n",
    "# !conda install --yes -c conda-forge pytorch-lightning\n",
    "# !conda install --yes -c conda-forge opencv\n",
    "# !conda update pytorch-lightning\n",
    "# !conda uninstall --yes pytorch-lightning\n",
    "# !conda install --yes -c conda-forge pytorch-lightning==0.9\n",
    "# !pip install pytorch-lightning==1.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "009eeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split,DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from helper import (scale, shift_crop_training_sample,\n",
    "                    crop_sample, NormalizeToTensor,bgr2rgb,rgb2bgr)\n",
    "from datasets import ALOVDataset, ILSVRC2014_DET_Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "# from convlstm import ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c741b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = 224\n",
    "# transform = NormalizeToTensor()\n",
    "# data_directory = '../data/'\n",
    "# alov = ALOVDataset(os.path.join(data_directory,\n",
    "#                        'imagedata++/'),\n",
    "#                        os.path.join(data_directory,\n",
    "#                        'alov300++_rectangleAnnotation_full/'),\n",
    "#                        transform, input_size)\n",
    "# alov.show_sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa3e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --load_fast false --logdir=lightning_logs/ --port=8008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7616e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self,data_directory = '../data/' ,unique_images=4,lambda_shift_frac= 5,lambda_scale_frac= 15,min_scale= -0.4, max_scale= 0.4):\n",
    "        super().__init__()\n",
    "        self.data_directory = data_directory\n",
    "        self.unique_images = unique_images\n",
    "        self.numsynthetic = 10\n",
    "        self.batch_size = self.numsynthetic * self.unique_images + self.unique_images\n",
    "        self.input_size = 224\n",
    "        self.transform = NormalizeToTensor()\n",
    "        self.bb_params = {\n",
    "            'lambda_shift_frac': lambda_shift_frac,\n",
    "            'lambda_scale_frac': lambda_scale_frac,\n",
    "            'min_scale': min_scale,\n",
    "            'max_scale': max_scale\n",
    "        }\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "    \n",
    "    def setup(self, stage=None): \n",
    "        alov = ALOVDataset(os.path.join(self.data_directory,\n",
    "                       'imagedata++/'),\n",
    "                       os.path.join(self.data_directory,\n",
    "                       'alov300++_rectangleAnnotation_full/'),\n",
    "                       self.transform, self.input_size)\n",
    "        alov_len = alov.x.shape[0]\n",
    "        print(\"alov len\", alov_len)\n",
    "        \n",
    "        imagenet = ILSVRC2014_DET_Dataset(os.path.join(self.data_directory,\n",
    "                                                  'ILSVRC2013_DET_val/'),\n",
    "                                                  os.path.join(self.data_directory,\n",
    "                                                  'ILSVRC2013_DET_bbox_val/'),\n",
    "                                                  self.bb_params,\n",
    "                                                  self.transform,\n",
    "                                                  self.input_size)\n",
    "        imagenet_len = imagenet.x.shape[0]\n",
    "        print(\"imgnet len\", imagenet_len)\n",
    "        self.datasets = [alov, imagenet]\n",
    "\n",
    "#         self.datasets = [alov]\n",
    "    \n",
    "        self.lens = [alov_len,imagenet_len]\n",
    "#         self.lens = [alov_len]\n",
    "        \n",
    "        alov_indices = np.arange(alov_len, dtype=np.int32)\n",
    "        np.random.shuffle(alov_indices)\n",
    "        \n",
    "        imagenet_indices = np.arange(imagenet_len,dtype=np.int32)\n",
    "        np.random.shuffle(imagenet_indices)\n",
    "\n",
    "        indices = [alov_indices,imagenet_indices]\n",
    "#         indices = [alov_indices]\n",
    "    \n",
    "        self.train_X = np.array([[i,j] for i in range(len(self.datasets)) for j in indices[i]])\n",
    "#         self.train_y = np.array([self.datasets[i].y[j] for i,j in self.train_X])\n",
    "        train = TensorDataset(torch.tensor(self.train_X))                       \n",
    "        self.track_train,self.track_val,self.track_test = random_split(train,[int(0.8*len(train)),int(0.1*len(train)),len(train)-int(0.8*len(train)) - int(0.1*len(train))])\n",
    "        print(len(self.track_train))\n",
    "        \n",
    "    def make_transformed_samples(self,data):\n",
    "        '''\n",
    "        Given a dataset, it picks a random sample from it and returns a batch\n",
    "        of (kGeneratedExamplesPerImage+1) samples. The batch contains true sample\n",
    "        from dataset and kGeneratedExamplesPerImage samples, which are created\n",
    "        artifically with augmentation by GOTURN smooth motion model.\n",
    "        '''\n",
    "#         print(data)\n",
    "        x1_batch = torch.Tensor(self.batch_size, 3,\n",
    "                                    self.input_size, self.input_size)\n",
    "        x2_batch = torch.Tensor(self.batch_size, 3,\n",
    "                                    self.input_size, self.input_size)\n",
    "        y_batch = torch.Tensor(self.batch_size, 4)\n",
    "        \n",
    "        for pos,tens in enumerate(data):\n",
    "            datasetidx, idx = tens[0][0],tens[0][1]\n",
    "            dataset = self.datasets[datasetidx]\n",
    "            orig_sample = dataset.get_orig_sample(idx)\n",
    "            true_sample, _ = dataset.get_sample(idx)\n",
    "            true_tensor = self.transform(true_sample)\n",
    "#             print(\"true tensor curbb\", true_tensor['currbb'])\n",
    "            # initialize batch with the true sample\n",
    "            temp_pivot = pos*(self.numsynthetic+1)\n",
    "            x1_batch[temp_pivot] = true_tensor['previmg']\n",
    "            x2_batch[temp_pivot] = true_tensor['currimg']\n",
    "            y_batch[temp_pivot] = true_tensor['currbb']\n",
    "\n",
    "            for i in range(self.numsynthetic):\n",
    "                sample = orig_sample\n",
    "                # unscaled current image crop with box\n",
    "                curr_sample, opts_curr = shift_crop_training_sample(sample, self.bb_params)\n",
    "                # unscaled previous image crop with box\n",
    "#                 print(\"curr sample curbb\", curr_sample['bb'])\n",
    "                prev_sample, opts_prev = crop_sample(sample)\n",
    "#                 print(\"prev sample curbb\", prev_sample['bb'])\n",
    "                scaled_curr_obj = scale(curr_sample, opts_curr,self.input_size,self.input_size)\n",
    "                scaled_prev_obj = scale(prev_sample, opts_prev,self.input_size,self.input_size)\n",
    "                training_sample = {'previmg': scaled_prev_obj['image'],\n",
    "                                   'currimg': scaled_curr_obj['image'],\n",
    "                                   'currbb': scaled_curr_obj['bb']}\n",
    "                sample = self.transform(training_sample)\n",
    "                x1_batch[temp_pivot + i + 1] = sample['previmg']\n",
    "                x2_batch[temp_pivot + 1] = sample['currimg']\n",
    "                y_batch[temp_pivot + i + 1] = sample['currbb']\n",
    "        \n",
    "#         print(y_batch)\n",
    "        return x1_batch, x2_batch, y_batch\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.track_train, batch_size=self.unique_images,collate_fn = self.make_transformed_samples, drop_last=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.track_val, batch_size= self.unique_images,collate_fn = self.make_transformed_samples, drop_last=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.track_test,batch_size= self.unique_images,collate_fn = self.make_transformed_samples, drop_last=True)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e411019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker(pl.LightningModule):\n",
    "    \n",
    "  def __init__(self,lr=1e-5,momentum = 0.9,weight_decay = 0.0005,lr_decay= 100000,gamma= 0.1):\n",
    "    super().__init__()\n",
    "    self.lr = lr\n",
    "    self.momentum = momentum\n",
    "    self.weight_decay = weight_decay\n",
    "    self.lr_decay = lr_decay\n",
    "    self.gamma = gamma\n",
    "    caffenet = models.alexnet(pretrained=True)\n",
    "    self.convnet = nn.Sequential(*list(caffenet.children())[:-1])\n",
    "    for param in self.convnet.parameters():\n",
    "        param.requires_grad = False\n",
    "    self.classifier = nn.Sequential(\n",
    "            nn.Linear(256*6*6*2, 4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            )\n",
    "    self.weight_init()\n",
    "    \n",
    "  def weight_init(self):\n",
    "    for m in self.classifier.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m.bias.data.fill_(1)\n",
    "            m.weight.data.normal_(0, 0.005)\n",
    "    \n",
    "\n",
    "  def forward(self, x1,x2):\n",
    "    batch_size, channels,width, height = x1.size()\n",
    "    x1 = self.convnet(x1)\n",
    "    x1 = x1.view(batch_size, 256*6*6)\n",
    "    x2 = self.convnet(x2)\n",
    "    x2 = x2.view(batch_size, 256*6*6)\n",
    "    x = torch.cat((x1, x2), 1)\n",
    "    z = self.classifier(x)\n",
    "#     print(\"z\", z)\n",
    "    return z\n",
    "\n",
    "  def training_step(self, train_batch, batch_idx):\n",
    "    x1,x2,y = train_batch\n",
    "#     print(\"Train gt\", y)\n",
    "#     print('-'*120)\n",
    "    logits = self.forward(x1, x2)\n",
    "#     print(\"Logits\", logits)\n",
    "#     print('#'*120)\n",
    "    loss_fn = torch.nn.L1Loss(size_average=False)\n",
    "    loss = loss_fn(logits,y)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, val_batch, batch_idx):\n",
    "    x1,x2,y = val_batch\n",
    "    logits = self.forward(x1,x2)\n",
    "    loss_fn = torch.nn.L1Loss(size_average=False)\n",
    "    loss = loss_fn(logits,y)\n",
    "#     print(\"y\", y)\n",
    "    return loss\n",
    "\n",
    "  def test_step(self, test_batch, batch_idx):\n",
    "    x1,x2,y = test_batch\n",
    "    logits = self.forward(x1,x2)\n",
    "    loss_fn = torch.nn.L2Loss(size_average=False)\n",
    "    loss = loss_fn(logits,y)\n",
    "    return loss\n",
    "      \n",
    "  def configure_optimizers(self):\n",
    "    optimizer =  torch.optim.SGD(self.parameters(),\n",
    "                          lr=self.lr,\n",
    "                          momentum=self.momentum,\n",
    "                          weight_decay=self.weight_decay)\n",
    "    scheduler =  torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                          step_size=self.lr_decay,\n",
    "                                          gamma=self.gamma)\n",
    "    return [optimizer],[scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9307f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MemoryNetTracker(pl.LightningModule):\n",
    "    \n",
    "#   def __init__(self,lr=1e-5,momentum = 0.9,weight_decay = 0.0005,lr_decay= 100000,gamma= 0.1):\n",
    "#     super().__init__()\n",
    "#     self.lr = lr\n",
    "#     self.momentum = momentum\n",
    "#     self.weight_decay = weight_decay\n",
    "#     self.lr_decay = lr_decay\n",
    "#     self.gamma = gamma\n",
    "#     resnet = models.resnet50(pretrained=True)\n",
    "#     self.res = nn.Sequential(*list(resnet.children())[:-1])\n",
    "#     for param in self.res.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     self.memory_network = nn.Sequential(\n",
    "#             ConvLSTM(2048*7*7, 4096, 3, 1),\n",
    "#             nn.LSTM(4096, 4096, 2),\n",
    "#             nn.Linear(4096, 4)\n",
    "#             )\n",
    "#     self.proposal_refinement = nn.Sequential(\n",
    "#             nn.Linear(4 + (2048*7*7), 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4)\n",
    "#             )\n",
    "# #     self.weight_init()\n",
    "    \n",
    "#   def weight_init(self):\n",
    "#     for m in self.classifier.modules():\n",
    "#         if isinstance(m, nn.Linear):\n",
    "#             m.bias.data.fill_(1)\n",
    "#             m.weight.data.normal_(0, 0.005)\n",
    "    \n",
    "\n",
    "#   def forward(self, x1,x2):\n",
    "#     batch_size, channels, width, height = x1.size()\n",
    "#     x1 = self.res(x1)\n",
    "#     x1_flat = x1.view(batch_size, 2048*7*7)\n",
    "#     x2 = self.res(x2)\n",
    "#     x = torch.cat((x1, x2), 2)\n",
    "#     x_init_pred = self.memory_network(x)\n",
    "#     x_prop = torch.cat((x_init_pred, x1_flat), 1)\n",
    "#     z = self.proposal_refinement(x_prop)\n",
    "#     return z\n",
    "\n",
    "#   def training_step(self, train_batch, batch_idx):\n",
    "#     x1,x2,y = train_batch\n",
    "#     logits = self.forward(x1,x2)\n",
    "#     loss_fn = torch.nn.L1Loss(size_average=False)\n",
    "#     loss = loss_fn(logits,y)\n",
    "#     return loss\n",
    "\n",
    "#   def validation_step(self, val_batch, batch_idx):\n",
    "#     x1,x2,y = val_batch\n",
    "#     logits = self.forward(x1,x2)\n",
    "#     loss_fn = torch.nn.L1Loss(size_average=False)\n",
    "#     loss = loss_fn(logits,y)\n",
    "# #     print(\"y\", y)\n",
    "#     return loss\n",
    "\n",
    "#   def test_step(self, test_batch, batch_idx):\n",
    "#     x1,x2,y = test_batch\n",
    "#     logits = self.forward(x1,x2)\n",
    "#     loss_fn = torch.nn.L1Loss(size_average=False)\n",
    "#     loss = loss_fn(logits,y)\n",
    "#     return loss\n",
    "      \n",
    "#   def configure_optimizers(self):\n",
    "#     optimizer =  torch.optim.SGD(self.parameters(),\n",
    "#                           lr=self.lr,\n",
    "#                           momentum=self.momentum,\n",
    "#                           weight_decay=self.weight_decay)\n",
    "#     scheduler =  torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "#                                           step_size=self.lr_decay,\n",
    "#                                           gamma=self.gamma)\n",
    "#     return [optimizer],[scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc133453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6a87e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['0.weight', '0.bias', '3.weight', '3.bias', '6.weight', '6.bias', '9.weight', '9.bias'])\n"
     ]
    }
   ],
   "source": [
    "data_module = TrackDataModule()\n",
    "\n",
    "# train\n",
    "model = Tracker()\n",
    "# model = Tracker.load_from_checkpoint(checkpoint_path=\"actual_train.ckpt\")\n",
    "trainer = pl.Trainer(gpus=1,max_epochs=1,log_every_n_steps=10,accelerator='dp',enable_checkpointing=True)\n",
    "# trainer = pl.Trainer(gpus=3,max_epochs=1,log_every_n_steps=10,enable_checkpointing=True)\n",
    "\n",
    "\n",
    "# trainer.test(datamodule= data_module,model=model)\n",
    "# get_metrics(model.test_labels,model.test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e22d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ALOV dataset...\n",
      "ALOV dataset parsing done.\n",
      "Total number of annotations in ALOV dataset = 16023\n",
      "alov len 16023\n",
      "Parsing ImageNet dataset...\n",
      "ImageNet dataset parsing done.\n",
      "Total number of annotations in ImageNet dataset = 40948\n",
      "imgnet len 40948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | convnet    | Sequential | 2.5 M \n",
      "1 | classifier | Sequential | 109 M \n",
      "------------------------------------------\n",
      "109 M     Trainable params\n",
      "2.5 M     Non-trainable params\n",
      "111 M     Total params\n",
      "446.201   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45576\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4a79976930478abf381a0cf0db6766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, data_module)\n",
    "trainer.save_checkpoint(\"train_ablation_L2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm = Tracker.load_from_checkpoint(checkpoint_path=\"train_model_nodrop.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db817364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c73f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = module.train_dataloader()\n",
    "# for ex in tqdm(loader):\n",
    "#     print(ex[0].shape,ex[1].shape,ex[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module.train_y[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(args.manual_seed)\n",
    "# torch.manual_seed(args.manual_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# checkpoint_steps = 20000  # save model after every 20000 steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9237b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([\"kawshik\",\"gayatri\",\"gokul\"])\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = TensorDataset(torch.Tensor(np.array([[1,2,3],[4,5,6]])),torch.Tensor(np.array([[1,2,3],[4,5,6]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6833ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shuffle()\n",
    "# print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alov_len = 10\n",
    "# imagenet_len = 15\n",
    "# datasets = [1,2]\n",
    "# a = np.arange(alov_len,dtype=np.int32)\n",
    "# np.random.shuffle(a)\n",
    "# b = np.arange(imagenet_len,dtype=np.int32)\n",
    "# np.random.shuffle(b)\n",
    "# indices = [a,b]\n",
    "# print(indices)\n",
    "# train_X = np.array([[i,j] for i in range(len(datasets)) for j in indices[i]])\n",
    "# print(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d0bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda60b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
